{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image, ImageEnhance\n",
    "from glob import glob as gl\n",
    "import PIL\n",
    "W = 224\n",
    "H = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_points(pts):\n",
    "\t# initialzie a list of coordinates that will be ordered\n",
    "\t# such that the first entry in the list is the top-left,\n",
    "\t# the second entry is the top-right, the third is the\n",
    "\t# bottom-right, and the fourth is the bottom-left\n",
    "\trect = np.zeros((4, 2), dtype = \"float32\")\n",
    "\t# the top-left point will have the smallest sum, whereas\n",
    "\t# the bottom-right point will have the largest sum\n",
    "\ts = pts.sum(axis = 1)\n",
    "\trect[0] = pts[np.argmin(s)]\n",
    "\trect[2] = pts[np.argmax(s)]\n",
    "\t# now, compute the difference between the points, the\n",
    "\t# top-right point will have the smallest difference,\n",
    "\t# whereas the bottom-left will have the largest difference\n",
    "\tdiff = np.diff(pts, axis = 1)\n",
    "\trect[1] = pts[np.argmin(diff)]\n",
    "\trect[3] = pts[np.argmax(diff)]\n",
    "\t# return the ordered coordinates\n",
    "\treturn rect\n",
    "\n",
    "def four_point_transform(image, pts):\n",
    "\t# obtain a consistent order of the points and unpack them\n",
    "\t# individually\n",
    "\trect = order_points(pts)\n",
    "\t(tl, tr, br, bl) = rect\n",
    "\t# compute the width of the new image, which will be the\n",
    "\t# maximum distance between bottom-right and bottom-left\n",
    "\t# x-coordiates or the top-right and top-left x-coordinates\n",
    "\twidthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "\twidthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "\tmaxWidth = max(int(widthA), int(widthB))\n",
    "\t# compute the height of the new image, which will be the\n",
    "\t# maximum distance between the top-right and bottom-right\n",
    "\t# y-coordinates or the top-left and bottom-left y-coordinates\n",
    "\theightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "\theightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "\tmaxHeight = max(int(heightA), int(heightB))\n",
    "\t# now that we have the dimensions of the new image, construct\n",
    "\t# the set of destination points to obtain a \"birds eye view\",\n",
    "\t# (i.e. top-down view) of the image, again specifying points\n",
    "\t# in the top-left, top-right, bottom-right, and bottom-left\n",
    "\t# order\n",
    "\tdst = np.array([\n",
    "\t\t[0, 0],\n",
    "\t\t[maxWidth - 1, 0],\n",
    "\t\t[maxWidth - 1, maxHeight - 1],\n",
    "\t\t[0, maxHeight - 1]], dtype = \"float32\")\n",
    "\t# compute the perspective transform matrix and then apply it\n",
    "\tM = cv2.getPerspectiveTransform(rect, dst)\n",
    "\twarped = cv2.warpPerspective(image, M, (maxWidth, maxHeight))\n",
    "\t# return the warped image\n",
    "\treturn warped\n",
    "\n",
    "def show(img, name = \"show\"):\n",
    "    if cf.show :\n",
    "        max_height = 400\n",
    "        max_width = 800\n",
    "        h, w = img.shape[:2]\n",
    "        r1 = max_height/h\n",
    "        r2 = max_width/w\n",
    "        r = min(r1, r2)\n",
    "        img = cv2.resize(img, (int(w*r), int(h*r)))\n",
    "        cv2.imshow(name, img)\n",
    "    \n",
    "\n",
    "def crop_object(file):\n",
    "    im = Image.open(file)\n",
    "    img = np.array(im)\n",
    "    h, w = img.shape[:2]\n",
    "    img = img[h//3: 2*h//3]\n",
    "    img0 = img.copy()\n",
    "\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    ret, thresh = cv2.threshold(img_gray, 80, 255, cv2.THRESH_BINARY)\n",
    "    # show(thresh, \"thresh\")\n",
    "    kernel = np.ones((7, 7),np.uint8)\n",
    "    opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
    "    # show(opening, \"opening\")\n",
    "\n",
    "    blur = cv2.GaussianBlur(opening,(315, 115),0)\n",
    "    # show(blur, \"blur\")\n",
    "\n",
    "    ret, thresh2 = cv2.threshold(blur, 80, 255, cv2.THRESH_BINARY)\n",
    "    ratio = np.sum(thresh2)/(255*img.shape[0]*img.shape[1])\n",
    "    spliter = int(img.shape[1]/(img.shape[0]*(ratio+0.1)))\n",
    "    thresh2[:, -50:]=0\n",
    "    for i in range(spliter):\n",
    "        pos = i*img_gray.shape[1]//(spliter)\n",
    "        thresh2[:, pos:pos+50] = 0\n",
    "\n",
    "    \n",
    "    contours, hierarchy = cv2.findContours(thresh2, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE) \n",
    "    \n",
    "    areas = []\n",
    "    for contour in contours:\n",
    "        areas.append(cv2.contourArea(contour))\n",
    "    arg_max = np.argsort(np.array(areas))[::-1]\n",
    "    num = min(spliter-1, len(contours))\n",
    "    out = []\n",
    "    boxes = []\n",
    "    for i in range(num):\n",
    "        index = arg_max[i]\n",
    "        rect = cv2.minAreaRect(contours[index])\n",
    "        box = cv2.boxPoints(rect)\n",
    "        box = np.int0(box)\n",
    "        cv2.drawContours(img,[box],0,(0,0,255), 15)\n",
    "        warped = four_point_transform(img0, box)\n",
    "        # show(warped, \"warped \"+str(i))\n",
    "        boxes.append(order_points(box))\n",
    "        out.append(warped)\n",
    "    show(img)\n",
    "    return np.array(out), np.array(boxes)\n",
    "\n",
    "def sort_box(out, boxes):\n",
    "    arg_sort = np.argsort(boxes[:, 0, 0])\n",
    "    print(arg_sort)\n",
    "\n",
    "    return out[arg_sort]\n",
    "\n",
    "def padding_to_square(img, W, H):\n",
    "    h, w = img.shape[:2]\n",
    "    out = np.zeros((H, W, 3), np.uint8)\n",
    "    r = min(W/w, H/h)\n",
    "    img = cv2.resize(img, (int(r*w), int(r*h)))\n",
    "    h, w = img.shape[:2]\n",
    "    out[(H-h)//2:(H-h)//2+h, (W-w)//2:(W-w)//2+w] = img\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = load_model(\"model.h5\")\n",
    "def predict(model, img):\n",
    "    img = padding_to_square(img, W, H)\n",
    "    # img = np.expand_dims(img, axis=2)\n",
    "    out = model.predict(np.array([img]), )[0][0]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_14980\\3122889841.py:112: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(out), np.array(boxes)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 0 2 4 6 8 3 5 1]\n",
      "1/1 [==============================] - 0s 174ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "[26.191607, 22.24044, 22.42993, 23.522778, 22.02022, 21.81428, 21.6696, 19.130503]\n",
      "Result: 22.377419\n"
     ]
    }
   ],
   "source": [
    "files = gl(\"2020_Nr63_Garne von Jan√üen/alpha130/*\")\n",
    "\n",
    "random = np.random.choice(files)\n",
    "spliter = 10\n",
    "out, boxes = crop_object(random)\n",
    "crops = sort_box(out, boxes)\n",
    "angles = []\n",
    "for i in range(crops.shape[0]-1):\n",
    "    angle = predict(model, crops[i])\n",
    "    angles.append(angle)\n",
    "\n",
    "print(angles)\n",
    "print(\"Result:\", np.mean(angles))\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "twist_angle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6b35ee8d5d34e8960c48046c53ac19d5ac5e69bec5b129720f002a75dba90304"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
